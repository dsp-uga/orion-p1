{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure and create the Spark Context object \n",
    "\n",
    "conf = SparkConf().setAppName(\"Project1\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Read the documents locally, one record correspond to one doc\n",
    "XTrainOri = sc.textFile(\"data_for_initial_local_training/X_train_vsmall.txt\").cache()\n",
    "YTrainOri = sc.textFile(\"data_for_initial_local_training/Y_train_vsmall.txt\").cache()\n",
    "\n",
    "\n",
    "# To read the documents on GCP\n",
    "#XTrainOri = sc.textFile(\"gs://uga-dsp/project1/train/X_train_vsmall.txt\").cache()\n",
    "#YTrainOri = sc.textFile(\"gs://uga-dsp/project1/train//Y_train_vsmall.txt\").cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a', 0), ('dedicated', 0), ('quot;snow', 0), ('desk&quot', 0), ('has', 0), ('been', 0), ('set', 0), ('up', 0), ('by', 0), ('the', 0)]\n"
     ]
    }
   ],
   "source": [
    "# split documents into words, remove punctuation, trainsform words to lower case\n",
    "\n",
    "# ? still need to remove quot from words, and punctuation in the middle of a word\n",
    "\n",
    "punctuation = sc.broadcast(\".,:;'!?&_-\")\n",
    "XTrainCP = XTrainOri.zipWithIndex().flatMap(lambda x: map(lambda e: (e, x[1]), x[0].split()))\\\n",
    "                    .map(lambda s: (s[0].strip(punctuation.value).lower(),s[1])) \n",
    "                    \n",
    "print(XTrainCP.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dedicated', 0), ('quot;snow', 0), ('desk&quot', 0), ('set', 0), ('up', 0), ('new', 0), ('york', 0), ('new', 0), ('jersey', 0), ('port', 0)]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stopwords using the file stopwords.txt provided in project0\n",
    "\n",
    "# ? Change source of stopwords\n",
    "stopWordsFile = sc.textFile(\"stopwords.txt\")\n",
    "stopWords = sc.broadcast(stopWordsFile.flatMap(lambda s: s.split()).collect())\n",
    "\n",
    "XTrainCPS = XTrainCP.filter(lambda s: s if s[0] not in stopWords.value and s[0] else None) \\\n",
    "                    \n",
    "print(XTrainCPS.take(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('rebounding', 46), 1), (('now', 18), 1), (('quot;foreign', 1), 1), (('generally', 51), 1), (('intentions', 24), 1), ((\"thursday's\", 35), 1), (('bounce', 8), 1), (('noting', 3), 1), (('annual', 67), 1), ((\"don't\", 3), 1), (('snow-melters', 0), 1), (('control', 47), 1), (('improvement', 4), 1), ((\"quot;there's\", 61), 1), (('passengers,&quot', 50), 1), (('+0.4', 19), 1), (('network', 58), 1), (('audit', 29), 2), (('49', 17), 2), (('monday', 36), 1), (('several', 12), 2), (('negotiating,&quot', 9), 1), (('term', 34), 1), (('49,744', 57), 1), (('643.75', 14), 1), (('access', 25), 1), (('paid', 50), 1), (('sickened', 12), 1), (('television', 34), 1), (('life', 51), 1), (('traditionally', 47), 1), (('buzz', 12), 1), (('declined', 38), 1), (('obstruction', 55), 1), (('wednesday', 67), 1), (('penalty', 36), 1), (('calls', 24), 1), (('prepare', 22), 1), (('two', 56), 1), (('garage', 5), 2), (('island', 61), 3), (('quot;i', 12), 1), ((\"i'm\", 47), 1), (('7', 61), 1), (('before', 34), 2), (('growth', 8), 2), (('major', 38), 1), (('issue', 15), 1), (('villa', 36), 1), (('serves', 61), 1), (('see', 47), 1), (('selling', 50), 1), (('1.825', 4), 1), (('lost', 44), 1), (('members', 50), 2), (('winston', 17), 1), (('three', 24), 2), (('rise', 51), 1), (('chinese-owned', 50), 1), (('statement', 16), 1), (('flights', 40), 1), (('loan', 67), 2), (('62', 35), 1), (('itself', 55), 2), (('rates', 34), 6), (('(mps)', 53), 1), (('matters', 40), 1), (('earlier', 31), 1), (('also', 5), 1), (('43.86', 50), 1), (('need', 67), 1), (('gmt', 39), 1), (('ravanelli', 26), 1), (('positions', 24), 2), (('microsystems', 18), 1), (('arafat', 66), 3), (('might', 51), 1), (('won', 65), 1), (('3.3950', 49), 1), (('announced', 5), 1), (('not', 65), 1), (('5240', 22), 1), (('presently', 53), 1), (('treatment', 61), 1), (('higher', 4), 1), (('(ktdc)', 41), 1), (('packet', 12), 1), (('(german', 34), 1), (('12', 44), 1), (('increased', 56), 1), (('expectation', 34), 1), (('rangebound', 24), 1), (('say', 66), 1), (('mainly', 37), 1), (('nuon', 9), 2), (('company', 51), 2), (('humidity', 0), 1), (('tnt', 17), 1), (('thanks', 36), 1), (('probably', 46), 1)]\n"
     ]
    }
   ],
   "source": [
    "# count the # of (word,index of document) pairs \n",
    "\n",
    "XTrainCPSC = XTrainCPS.map(lambda s: (s,1))\\\n",
    "                        .reduceByKey( lambda a,b: a + b)\n",
    "print(XTrainCPSC.take(100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, {'7706': 1, '250': 1, 'conditions': 1, 'quot;we': 2, 'jfk': 1, 'kennedy': 1, 'feeley': 1, 'round': 1, 'new': 3, 'almost': 1, 'f': 1, 'blowers': 1, 'including': 1, 'ground': 1, 'blast': 1, 'snow': 1, 'massive': 1, 'officer': 1, 'few': 1, 'employees': 1, \"don't\": 1, '171': 2, 'standby': 1, 'help': 1, 'latest': 1, 'carefully': 1, 'national': 1, 'laguadria': 1, 'operations': 2, 'temperatures': 1, 'airport': 2, 'accordingly': 1, 'prevent': 1, 'quot;snow': 2, 'key': 2, 'private': 1, 'anticipate': 1, 'air': 2, 'facility-specific': 1, 'airports': 3, 'more': 1, 'inground': 1, 'humidity': 1, 'pieces': 1, 'day': 1, 'plan': 1, 'staff': 1, 'chief': 1, 'tracks': 1, 'react': 1, '5,100': 1, 'snow-melters': 1, 'technology': 1, \"york's\": 1, 'tons': 1, 'year': 2, 'moving': 1, 'newsroom': 1, 'de-icing': 1, 'david': 1, 'transmitting': 1, '542': 2, 'special': 1, 'york': 1, 'updated': 1, 'data': 1, 'companies': 1, \"what's\": 1, 'desk&quot': 2, 'use': 1, 'sand': 1, 'reports': 2, 'set': 1, 'deploy': 1, \"day's\": 1, 'up': 2, 'each': 4, 'cargo': 2, 'disruption': 1, 'authority': 3, '5017': 1, 'john': 1, 'sensors': 1, 'maintenance': 1, 'operates': 1, 'facility.&quot': 1, 'through': 1, 'allows': 1, 'equipment': 4, 'dewpoint': 1, 'monitor': 1, 'deployment': 1, 'us&quot': 1, 'service': 1, 'analyse': 1, 'hit': 1, 'snow-fighting': 1, 'fax+44': 1, 'jersey': 1, 'wait': 1, 'laguardia': 1, 'winter': 2, 'forecasts': 1, 'advance': 1, 'counter': 1, 'newark': 2, 'coming': 1, 'direction': 1, 'supplements': 1, 'port': 2, 'dedicated': 2, 'travellers': 1, 'patterns': 1, 'windspeed': 1, 'tel+44': 1, 'salt': 1, 'personnel': 1, 'weather': 5, 'times': 1, 'harsh': 1, 'sit': 1}), (64, {'chain': 2, 'stores': 2, 'japanese': 1, 'among': 1, 'august': 2, 'sales': 2, 'companies': 1, 'conducted': 1, 'fell': 2, 'wednesday': 1, '7,805': 1, '172': 1, 'trillion': 1, '1.40': 1, 'ago': 1, 'earlier': 1, 'association': 2, '5.4': 1, 'yen': 1, 'july': 1, '132': 1, 'percent': 2, 'covered': 1, 'survey': 1, 'statement': 1, 'japan': 1, 'year': 2, 'more': 1, 'outlets': 2, '0.2': 1})]\n"
     ]
    }
   ],
   "source": [
    "# the structure of output: (index of document, dictionary of {word: count of word})\n",
    "\n",
    "XTrainDict = XTrainCPSC.map(lambda x: (x[0][1],(x[0][0],x[1])))\\\n",
    "                            .groupByKey()\\\n",
    "                            .map(lambda x: (x[0],dict(x[1])))\n",
    "\n",
    "\n",
    "print(XTrainDict.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
